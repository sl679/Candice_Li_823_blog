{
  
    
        "post0": {
            "title": "823 HW3 -Candice Li",
            "content": "import csv import datetime import numpy as np import pandas as pd import matplotlib.pyplot as plt from ipywidgets import widgets . Read in the datasets . df_death = pd.read_csv(&#39;data/malaria_deaths.csv&#39;) df_inc = pd.read_csv(&#39;data/malaria_inc.csv&#39;) df_death_age =pd.read_csv(&#39;data/malaria_deaths_age.csv&#39;) . Rename the columns . After renaming the columns, the column names of the dataset are more concise and easier to use. . df_death.rename(columns = {&quot;Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)&quot;: &quot;death_rate&quot;}, inplace = True) df_inc.rename(columns = {&quot;Incidence of malaria (per 1,000 population at risk) (per 1,000 population at risk)&quot;: &quot;death_inc&quot;}, inplace = True) . Import the packages going to be used . I choose to use plotly for graphing . import plotly.io as pio import plotly.express as px import plotly.offline as py . Plot 1 . for &#39;malaria_deaths.csv&#39; data . fig1 = px.bar(df_death, x=&#39;Year&#39;, y=&#39;death_rate&#39;, color=&#39;Entity&#39;, title=&#39;Histogram of number of death of People due to Malaria in various countries from 1990 to 2016&#39;) fig1.update_layout() . def create_scatter1(select_country): with plt.style.context(&quot;ggplot&quot;): fig = plt.figure(figsize=(8,4)) plt.scatter(x = df_death[df_death.Entity == select_country].Year, y = df_death[df_death.Entity == select_country].death_rate, s = 10 ) plt.xlabel(&quot;Year&quot;) plt.title(&quot;Death Rate of Malaria from 1990 to 2016 in %s&quot; % (select_country)) . widgets.interact(create_scatter1, select_country = df_death[&quot;Entity&quot;].unique()); . Plot 2 . for &#39;malaria_inc.csv&#39; data . def create_scatter2(select_country): with plt.style.context(&quot;ggplot&quot;): fig = plt.figure(figsize=(8,4)) plt.scatter(x = df_inc[df_inc.Entity == select_country].Year, y = df_inc[df_inc.Entity == select_country].death_inc, s = 10 ) plt.xlabel(&quot;Year&quot;) plt.ylabel(&quot;Incidence of malaria (per 1,000 population at risk)&quot;) plt.title(&quot;Death Rate of Malaria from 1990 to 2016 in %s&quot; % (select_country)) . widgets.interact(create_scatter2, select_country = df_inc[&quot;Entity&quot;].unique()); . Plot 3 . for &#39;malaria_deaths.csv&#39; data . def create_scatter3(select_country, select_age): with plt.style.context(&quot;ggplot&quot;): fig = plt.figure(figsize=(10,6)) selected_df = df_death_age.loc[(df_death_age.entity == select_country) &amp; (df_death_age.age_group == select_age)] plt.scatter(x = selected_df.year, y = selected_df.deaths, s = 10 ) plt.xlabel(&quot;Year&quot;) plt.ylabel(&quot;Number of Deaths&quot;) plt.title(&quot;Deaths of Malaria from 1990 to 2016 in %s for people %s&quot; % (select_country, select_age)) . widgets.interact(create_scatter3, select_country = df_death_age[&quot;entity&quot;].unique(), select_age = df_death_age[&quot;age_group&quot;].unique()); .",
            "url": "https://sl679.github.io/Candice_Li_823_blog/2021/11/14/HW3_Li_Candice.html",
            "relUrl": "/2021/11/14/HW3_Li_Candice.html",
            "date": " • Nov 14, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "823 HW1-Candice Li",
            "content": "Problem 6; Sum square difference; Solved by 496303 people . We define a function called sum_square_diff. First, we find the sum of squares of the of the numbers in a certain range. Then, we find the square of the sum of the numbers in the certain range. The we find the difference between the two results. We get 2640 for the difference. . def sum_square_diff(n): &quot;&quot;&quot;Get the difference between the sum of the squares of the first one hundred natural numbers and the square of the sum. n : integer The integer we want to conduct sum square difference on. &quot;&quot;&quot; sum_square = 0 square_sum = 0 for i in range(1, n+1): sum_square = sum_square + (i**2) for i in range(1, n+1): square_sum = square_sum + i square_sum = (square_sum ** 2) result = square_sum - sum_square return result print(sum_square_diff(10)) . 2640 . Problem 34; Digit factorials; Solved by 59089 people . We define a function called get_sum() to find the sum of all the curious numbers like 145. First we define a function to find the digits of a number called the get_digits. In this function, we convert the number to a string and put the digits in an array and then return the array. Then, we define the get_fuctorial function to get the factorial of a certain number. In this function, we use recursion. The base case is defined to be when the number is 1 or 0, else we multiply the number to the total result and minus 1 from the number and then pass it back to the function. After defining these functions, we find the number that the sum of the factorial of its digits equals itself and sum them up. For numbers between 3 and 9999999 because if all the digits are 9, the digits that possible fullfill the requirement of the curious number is around 7. For every number in this range, we pass every digits and get the sum of the factorial of them and compare the sum with the original number. If the two values are equal, then we add them into the result. Finally, we got 40730 for the sum. . def get_sum(): &quot;&quot;&quot;Get the sum of curious numbers which equals the sum of the factorial of its digits. &quot;&quot;&quot; def get_digits(number): &quot;&quot;&quot;Get the digints of a certain number number: integer The intger that we want to get digits of. &quot;&quot;&quot; digs = [] for i in str(number): digs.append(i) return digs def get_factorial(num): &quot;&quot;&quot;Get the factorial of a number num: integer The integer we want to get factorial of. &quot;&quot;&quot; if (num == 1 or num == 0): return 1 else: return num * get_factorial(num-1) total_sum = 0 for number in range(3, 1499999): digits = get_digits(number) fac_sum = 0 for dig in digits: fac_sum = fac_sum + get_factorial(int(dig)) if (fac_sum == number): total_sum = total_sum + number return(total_sum) print(get_sum()) . 40730 . Problem 112; Bouncy numbers; Solved by 24434 people. . We define a function called get_lim() to get the least number for which the proportion of bouncy numbers is exactly 99%. Under this function, first we call a function to find the digits of a number called the get_digits. In this function, we convert the number to a string and put the digits in an array and then return the array. Then, we define an is_increase() function to check if the number is an increasing number. In this function, we first call the get_digits() function to get digits of the number; then we compare the digits with the next digits to see if it is an increasing number. Then, we define an is_decrease() function to check if the number is a decreasing number. In this function, we first call the get_digits() function to get digits of the number; then we compare the digits with the next digits to see if it is a decreasing number. Thirdly, we define a is_bouncy() function to check if the number is a bouncy number. We call the is_decrease() and is_increase() function defined earlier. If the number is neither increasing or decreasing, then it is a bouncy number. Finally, we create a while loop to append every bouncy number in an array until the percent of bouncy numbers in the range get 99%. The result we got is 1587000. . def get_lim(): &quot;&quot;&quot;Find the least number for which the proportion of bouncy numbers is exactly 99% &quot;&quot;&quot; def get_digits(number): &quot;&quot;&quot; Get the dignits of integers. number: integer The integer we want to get digits of. &quot;&quot;&quot; digs = [] for i in str(number): digs.append(i) return digs def is_increase(number): &quot;&quot;&quot;Check if the integer is an increasing number number: integer The interger we want to check if is an increasing number. &quot;&quot;&quot; digits = get_digits(number) result = 0 for i in range(0,len(digits) - 1): if (int(digits[i+1]) &gt;= int(digits[i])): result = result + 0 else: result += 1 if (result == 0): return 1 else: return 0 return result def is_decrease(number): &quot;&quot;&quot;Check if the integer is a decreasing number number: integer The interger we want to check if is a decreasing number. &quot;&quot;&quot; digits = get_digits(number) result = 0 for i in range(0,len(digits) - 1): if (int(digits[i+1]) &lt;= int(digits[i])): result = result + 0 else: result += 1 if (result == 0): return 1 else: return 0 return result def is_bouncy(number): &quot;&quot;&quot;Check if the integer is a bouncy number number: integer The interger we want to check if is a bouncy number. &quot;&quot;&quot; if ((is_increase(number) != 1) &amp; (is_decrease(number) != 1)): return 1 else: return 0 number = 0; percent = 0; b =[] while percent &lt; 0.99: number += 1 if is_bouncy(number): b.append(number) percent = len(b)/number print(&quot;The least number for which the proportion of bouncy numbers is exactly 99% is &quot; + str(number)) get_lim() . The least number for which the proportion of bouncy numbers is exactly 99% is 1587000 .",
            "url": "https://sl679.github.io/Candice_Li_823_blog/2021/11/14/HW1_Li_Candice.html",
            "relUrl": "/2021/11/14/HW1_Li_Candice.html",
            "date": " • Nov 14, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "823 HW5 Candice Li",
            "content": "import the needed packages . import PIL from PIL import Image import glob import os import matplotlib.pyplot as plt import numpy as np import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers from tensorflow.keras.models import Sequential . Define file path . path_train = &#39;train/&#39; path_test = &#39;test/&#39; . batch_size = 32 img_height = 180 img_width = 180 . Read training data and split into training and validation at ratio 0.2 . tr_ds = tf.keras.utils.image_dataset_from_directory( path_train, validation_split=0.2, subset=&quot;training&quot;, seed =123, image_size=(img_height, img_width), batch_size=batch_size) . Found 1019 files belonging to 3 classes. Using 816 files for training. . val_ds = tf.keras.utils.image_dataset_from_directory( path_train, validation_split=0.2, subset=&quot;validation&quot;, seed =123, image_size=(img_height, img_width), batch_size=batch_size) . Found 1019 files belonging to 3 classes. Using 203 files for validation. . Show some sample plots . plt.figure(figsize=(10, 10)) for images, labels in tr_ds.take(1): for i in range(9): ax = plt.subplot(3, 3, i + 1) plt.imshow(images[i].numpy().astype(&quot;uint8&quot;)) plt.title(class_names[labels[i]]) plt.axis(&quot;off&quot;) . for image_batch, labels_batch in tr_ds: print(image_batch.shape) print(labels_batch.shape) break . (32, 180, 180, 3) (32,) . Configure the dataset for performance . AUTOTUNE = tf.data.AUTOTUNE tr_ds = tr_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE) val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE) . Standardize the data . normalization_layer = layers.Rescaling(1./255) . normalized_ds = tr_ds.map(lambda x, y: (normalization_layer(x), y)) image_batch, labels_batch = next(iter(normalized_ds)) first_image = image_batch[0] # Notice the pixel values are now in `[0,1]`. print(np.min(first_image), np.max(first_image)) . 0.0 0.99623764 . Create the model and use dropout to avoid overfitting . num_classes = 3 model = Sequential([ data_augmentation, layers.Rescaling(1./255), layers.Conv2D(16, 3, padding=&#39;same&#39;, activation=&#39;relu&#39;), layers.MaxPooling2D(), layers.Conv2D(32, 3, padding=&#39;same&#39;, activation=&#39;relu&#39;), layers.MaxPooling2D(), layers.Conv2D(64, 3, padding=&#39;same&#39;, activation=&#39;relu&#39;), layers.MaxPooling2D(), layers.Dropout(0.2), layers.Flatten(), layers.Dense(128, activation=&#39;relu&#39;), layers.Dense(num_classes) ]) . Compile the model . model.compile(optimizer=&#39;adam&#39;, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[&#39;accuracy&#39;]) . Model summary . model.summary() . Model: &#34;sequential_3&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= sequential_1 (Sequential) (None, 180, 180, 3) 0 rescaling_3 (Rescaling) (None, 180, 180, 3) 0 conv2d_6 (Conv2D) (None, 180, 180, 16) 448 max_pooling2d_6 (MaxPooling (None, 90, 90, 16) 0 2D) conv2d_7 (Conv2D) (None, 90, 90, 32) 4640 max_pooling2d_7 (MaxPooling (None, 45, 45, 32) 0 2D) conv2d_8 (Conv2D) (None, 45, 45, 64) 18496 max_pooling2d_8 (MaxPooling (None, 22, 22, 64) 0 2D) dropout_1 (Dropout) (None, 22, 22, 64) 0 flatten_2 (Flatten) (None, 30976) 0 dense_4 (Dense) (None, 128) 3965056 dense_5 (Dense) (None, 3) 387 ================================================================= Total params: 3,989,027 Trainable params: 3,989,027 Non-trainable params: 0 _________________________________________________________________ . Train the model . epochs = 15 history = model.fit( tr_ds, validation_data=val_ds, epochs=epochs ) . Epoch 1/15 26/26 [==============================] - 12s 432ms/step - loss: 1.0776 - accuracy: 0.5453 - val_loss: 0.7421 - val_accuracy: 0.6404 Epoch 2/15 26/26 [==============================] - 11s 430ms/step - loss: 0.6459 - accuracy: 0.7451 - val_loss: 0.4480 - val_accuracy: 0.8128 Epoch 3/15 26/26 [==============================] - 11s 427ms/step - loss: 0.5108 - accuracy: 0.8027 - val_loss: 0.3614 - val_accuracy: 0.8276 Epoch 4/15 26/26 [==============================] - 11s 430ms/step - loss: 0.4420 - accuracy: 0.8419 - val_loss: 0.4455 - val_accuracy: 0.8128 Epoch 5/15 26/26 [==============================] - 11s 427ms/step - loss: 0.4379 - accuracy: 0.8321 - val_loss: 0.4074 - val_accuracy: 0.8276 Epoch 6/15 26/26 [==============================] - 11s 431ms/step - loss: 0.3740 - accuracy: 0.8505 - val_loss: 0.3542 - val_accuracy: 0.8571 Epoch 7/15 26/26 [==============================] - 11s 424ms/step - loss: 0.3789 - accuracy: 0.8542 - val_loss: 0.4123 - val_accuracy: 0.8621 Epoch 8/15 26/26 [==============================] - 11s 429ms/step - loss: 0.3630 - accuracy: 0.8615 - val_loss: 0.3222 - val_accuracy: 0.8670 Epoch 9/15 26/26 [==============================] - 11s 424ms/step - loss: 0.3783 - accuracy: 0.8493 - val_loss: 0.3583 - val_accuracy: 0.8719 Epoch 10/15 26/26 [==============================] - 11s 427ms/step - loss: 0.3393 - accuracy: 0.8664 - val_loss: 0.3283 - val_accuracy: 0.8818 Epoch 11/15 26/26 [==============================] - 11s 425ms/step - loss: 0.3311 - accuracy: 0.8701 - val_loss: 0.2955 - val_accuracy: 0.8670 Epoch 12/15 26/26 [==============================] - 11s 442ms/step - loss: 0.3095 - accuracy: 0.8811 - val_loss: 0.4409 - val_accuracy: 0.8473 Epoch 13/15 26/26 [==============================] - 11s 425ms/step - loss: 0.2825 - accuracy: 0.8848 - val_loss: 0.3919 - val_accuracy: 0.8621 Epoch 14/15 26/26 [==============================] - 11s 433ms/step - loss: 0.2888 - accuracy: 0.8934 - val_loss: 0.3586 - val_accuracy: 0.8768 Epoch 15/15 26/26 [==============================] - 12s 472ms/step - loss: 0.2819 - accuracy: 0.8824 - val_loss: 0.3863 - val_accuracy: 0.8571 . Visualize training results . acc = history.history[&#39;accuracy&#39;] val_acc = history.history[&#39;val_accuracy&#39;] loss = history.history[&#39;loss&#39;] val_loss = history.history[&#39;val_loss&#39;] epochs_range = range(epochs) plt.figure(figsize=(8, 8)) plt.subplot(1, 2, 1) plt.plot(epochs_range, acc, label=&#39;Training Accuracy&#39;) plt.plot(epochs_range, val_acc, label=&#39;Validation Accuracy&#39;) plt.legend(loc=&#39;lower right&#39;) plt.title(&#39;Training and Validation Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(epochs_range, loss, label=&#39;Training Loss&#39;) plt.plot(epochs_range, val_loss, label=&#39;Validation Loss&#39;) plt.legend(loc=&#39;upper right&#39;) plt.title(&#39;Training and Validation Loss&#39;) plt.show() . x_train = np.concatenate([x for x, y in tr_ds], axis = 0) y_train = np.concatenate([y for x, y in tr_ds], axis = 0) x_test = np.concatenate([x for x, y in te_ds], axis = 0) y_test = np.concatenate([y for x, y in te_ds], axis = 0) . Evaluate the model using the test data using evaluate . print(&quot;Evaluate on test data&quot;) results = model.evaluate(x_test, y_test, batch_size=128) print(&quot;test loss, test acc:&quot;, results) . Evaluate on test data 2/2 [==============================] - 1s 170ms/step - loss: 0.2914 - accuracy: 0.8833 test loss, test acc: [0.29136383533477783, 0.8833333253860474] . p_path = &#39;purple_drangonfly.jpg&#39; img_p = PIL.Image.open(p_path) plt.imshow(img_p) plt.show() img = tf.keras.utils.load_img( p_path, target_size=(img_height, img_width) ) img_array = tf.keras.utils.img_to_array(img) img_array = tf.expand_dims(img_array, 0) # Create a batch predictions = model.predict(img_array) score = tf.nn.softmax(predictions[0]) print( &quot;This image most likely belongs to {} with a {:.2f} percent confidence.&quot; .format(class_names[np.argmax(score)], 100 * np.max(score)) ) . This image most likely belongs to dragonflies with a 97.52 percent confidence. . Use shapley additive explanations to explain the output of model . explainer = shap.GradientExplainer(model, x_train) . sv = explainer.shap_values(x_test[:10]) . `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model. . shap.image_plot([sv[i] for i in range(3)], x_test[85:88]) . class_names . [&#39;beetles&#39;, &#39;cockroach&#39;, &#39;dragonflies&#39;] .",
            "url": "https://sl679.github.io/Candice_Li_823_blog/2021/11/14/823HW5_Li_Candice.html",
            "relUrl": "/2021/11/14/823HW5_Li_Candice.html",
            "date": " • Nov 14, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "823 HW2 -Candice Li",
            "content": "In order to find the first 10-digit prime in the decimal expansion of 17π, three functions were defined. . Import libraries going to be used . import math import decimal try: from sympy.mpmath import mp except ImportError: from mpmath import mp . The function expansion_generater is used to get n places after the decimal point for irrational number. First the decimal places after the decimal point is defined to be 1000 so that it is long enough to find the target segment. Then, the actual expression being used is genrated based on the input parameters. In this program, only e and π are being considered. Then, the part after the decimal point of the expression with desired length is being extracted and returned. . def expansion_generater(n, symbol, time): &quot;&quot;&quot;Get n places after the decimal point for irrational number. n : int The length of the wanted number after decimal places. &quot;&quot;&quot; mp.dps = 1000 if symbol == &#39;pi&#39;: a = mp.pi elif symbol == &#39;e&#39;: a = mp.e exp = a*time before_dec, after_dec = int(exp), exp - int(exp) return str(after_dec)[2:n+2] . The function is_prime is used to check if an integer is a prime number. First, special cases like 0, 1, and 2 are being accounted for. 0, 1 are hard-coded to be not prime and 2 is hard-coded to be prime. Secondly, all the even numbers are coded to be not prime. Then we check if the square root of the number can be diviide by any number smaller than itself. If there is one, then this number is not prime. Otherwise, it is a prime number. . def is_prime(n): &quot;&quot;&quot;Check if an integer is a prime number. n : int The integer we want to check if it is prime. &quot;&quot;&quot; if n == 0 or n == 1: return False elif n == 2: return True elif (n &gt; 2 and n % 2 == 0): return False else: for i in range (3, 1 + math.floor(math.sqrt(n)), 2): if n % i == 0: return False return True . The function get_window is used to get all the integers with desired length in an expression. First, the expression is converted from integer to string. Secondly, a list is created to store the integers. Then, we start from the first index take out every integer segment with desired length. . def get_window(n, expression): &quot;&quot;&quot;Get the integers of length n in an expression. n : int The length of the wanted intger in the expression. &quot;&quot;&quot; expression = str(expression) result = [] for i in range(0, len(expression)): if len(expression[i:i+n]) == n: result.append(expression[i:i+n]) return result . The function find_n_digit_prime is the function that calls all of the functions written above and return the first value that satisfy the requirement. First, we get the segments of desried length using the function get_window and expansion_generator. expansion_generator returns the expression based on input and get_window get the segments with certain lenth in the expression. The, we store the segments if it has the same length with the desired length (the length may be shorter when reaching the end of the expression). Fianlly, we return the first segment in this list. This interger will be the final answer from this program. . def find_n_digit_prime(total_len, symbol, time, seg_len): segments = get_window(seg_len, expansion_generater(total_len, symbol, time)) found = [] for j in range (0, len(segments)): if is_prime(int(segments[j])): found.append(int(segments[j])) return found[0] . Run the code and get the answer for the first 10-digit prime in the decimal expansion of 17&#960;. . answer = find_n_digit_prime(1000, &quot;pi&quot;, 17, 10) print(&quot;The first 10-digit prime in the decimal expansion of 17π is &quot;+ str(answer) +&quot;.&quot;) . The first 10-digit prime in the decimal expansion of 17π is 8649375157. . Unit tests . Test for funtion expansion_generater . import unittest . class TestNotebook(unittest.TestCase): def expansion_generater(self): self.assertEqual(expansion_generater(10, &#39;pi&#39;, 1), 1415926535) self.assertEqual(expansion_generater(11, &#39;2&#39;, 2), 43656365692) unittest.main(argv = [&#39;&#39;], verbosity = 2, exit = False) . - Ran 0 tests in 0.000s OK . &lt;unittest.main.TestProgram at 0x7fe6ee1b1210&gt; . Test for funtion expansion_generater . class TestNotebook(unittest.TestCase): def is_prime(self): self.assertEqual(is_prime(150), False) self.assertEqual(is_prime(11), True) self.assertEqual(is_prime(2), True) unittest.main(argv = [&#39;&#39;], verbosity = 2, exit = False) . - Ran 0 tests in 0.000s OK . &lt;unittest.main.TestProgram at 0x7fe6ee24f210&gt; . Test for funtion get_window . class TestNotebook(unittest.TestCase): def get_window(self): self.assertEqual(get_window(1, 12345), [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;]) self.assertEqual(get_window(2, 12345), [&#39;12&#39;, &#39;23&#39;, &#39;34&#39;, &#39;45&#39;]) self.assertEqual(get_window(3, 12345), [&#39;123&#39;, &#39;234&#39;, &#39;345&#39;]) unittest.main(argv = [&#39;&#39;], verbosity = 2, exit = False) . - Ran 0 tests in 0.000s OK . &lt;unittest.main.TestProgram at 0x7fe6ee1d4050&gt; . Test for funtion find_first_ten_digit_prime . class TestNotebook(unittest.TestCase): def test_n_ten_digit_prime(self): self.assertEqual(find_first_ten_digit_prime(1000, &#39;e&#39;, 1, 10), 7427466391) unittest.main(argv = [&#39;&#39;], verbosity = 2, exit = False) . test_n_ten_digit_prime (__main__.TestNotebook) ... ok - Ran 1 test in 0.175s OK . &lt;unittest.main.TestProgram at 0x7fe6ee223390&gt; .",
            "url": "https://sl679.github.io/Candice_Li_823_blog/2021/09/17/823HW2_Li_Candice.html",
            "relUrl": "/2021/09/17/823HW2_Li_Candice.html",
            "date": " • Sep 17, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://sl679.github.io/Candice_Li_823_blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://sl679.github.io/Candice_Li_823_blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://sl679.github.io/Candice_Li_823_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sl679.github.io/Candice_Li_823_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}